Things that i find useful for understanding AI:
- the Transformer
- the entire process that shapes the modal weights
- the entire process that shapes the model output
- since i as a user practically never interface with a base model, understanding how web interface, api, app, cursor, claude code, etc. shape the output
- Scaling Laws
- the various METR graphs
- costs falling over time
- capabilities over time
- AI Theory of Mind
- you will have better results if you try to model a mind
- messages from Janus space
- edit your prompts, observe the difference, edit your prompts again
- many principles that work for running organisations are really principles for managing context, thus they translate to using AI almost one to one
- e.g. unit tests, clear specs, communicate cleary, treating AI as a bright intern or a genius employee that is constantly having their first day, almost all software production practices done in large orgs work out of the box and have significant returns
- the Jagged Frontier of capability
- understanding the strengths, weaknesses and idiosynchracies of models
- which is somewhat downstream of how they are build and trained, but are also related to what the major labs value and build. e.g. swe being a natural strength of llms because we have much semantically dense text aka code, and also the people who build AI are SWE and their natural preferences and goals are SWE lense influenced
- using the latest model: there are differences at the frontier and models advance every few months or so. also understanding that Thinking is a step change. please use thinking. so pay for the good models.
- maintain your own benchmark and run it against the models periodically, pick something you are good at evaluating
- using Claude Code and similiar future agents: lots of thoughts here but thats getting super specific, such as setting up skills, look into producing techniques, managing techniques and again how to run larger orgs.
- adopt a mindset of ambition and agency. the frontier models are hecking smart and can solve many problems that can be automated or solved by applying code. they will often tell you how if you ask. 'It would be useful if we could do x. AI how can we do x?'
- honest numbers on energy and water consumption of AI and Data Centers
- the economy: impact on the labor market, impact on growth, infrastructure build out
- society stuff: AI boyfriends, sycophancy, social media and tv related harms but in the shapes they will take for AI, laws and buercracy, learning and school, copyright
- safety: x-risk, mundane risk. 
- get involved

- practical examples of mundane utilty generated by AI for game developers: i should pull from many of my current projects

- multi modal AI: the image generation tools and how they work. i need to do research dive their cause i dont understand them as deeply as i do llms

- AI ethics: i dont want to be preachy. i have opinions that round a lot to the classic liberalism. but i see that people can disagree here about optimal policy. i'd much rather understand my role as a researcher or policy advisor? helping students to think clearly and make their own decisions.

Collaboration: i think most of that is handled by using git and claude.mds no? or rather you first have to learn collaboration patterns for humans and then you can apply them to the AI special case

QA: unit test. unit test. unit test.
- though i find that me being a better SWE i get better output because i can articulate better what i want. i suspect that sometimes in domains were i know less or when i observe someone with less swe expertise, they ask for something hacky or abstractly dumb, but they dont realise it. and the AI model being in model being in the default helpful assitant basin executes. using Opus 4.5 i find that i super rarely have to do significant QA, other then the same i would do when working with a human. unit tests, and playtesting the game. i just have to be specific when planning the feature and take a step back and ask Claude: 'you likely have more technical expertise, what would you do here and why?' then i can verify if the model is missing any context or has a false assumption and i can correct that miscommunication. general note: it is now far more likely that i simply miscommunicated not that the model didnt understand. you can fall into a habit of lazyness or short prompts

Fine Tuning i find not to be necessary at all. its too much effort for designers. and the gains are not that large. better to use a tool here and let somebody else do it

RAG/KNowledge Base. this is i think Claude Code or agent related. yes, keep good clear docs that do not contradict. though again that is general good advice for humans and one of those cases were suddenly with AI it pays of doubly

Local vs Cloud: use the frontier models cause they are the best. raw capability > speed > cost. also for privacy just get a enterprise account or dont worry too much

when not to use AI: here i think that is best handled by liberalism. everyone can make their choice. i can give some tactical business advice related to PR and i should stress that you should think. keep your brain on. do not abdicate, but you can (should? yes should because that brings better mental habits for myself. communication, positive sum thinking, etc. all the good stuff) treat a AI as a collaborate or peer. why not?

Engine Stuff: pick an engine with AI readable files, but soon that will be all. right now i'd favor Godot over unity but since Opus 4.5 and Unity 6 that works well too. for unity you can simply tell Claude to build itself tools for better understanding scenes or manipulating unity editor stuff

Playtesting: using AI for QA and especially sort of automated playing the game and modelling a player is super interestting. i havent really seen a good example in practice, but it should be possible if you are clever about it

Accessibilty: huge mundane utility gain, yes.

